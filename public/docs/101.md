# 人工智能史

**人工智能的历史**源远流长。在古代的[神话](https://zh.wikipedia.org/wiki/神話)[传说](https://zh.wikipedia.org/wiki/传说)中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[[1\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-FOOTNOTEMcCorduck2004-1)现代意义上的[AI](https://zh.wikipedia.org/wiki/人工智能)始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑](https://zh.wikipedia.org/wiki/電腦)的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。

1956年，[人工智能](https://zh.wikipedia.org/wiki/人工智能)的研究领域确立于在[达特茅斯学院](https://zh.wikipedia.org/wiki/达特茅斯学院)举行的[会议](https://zh.wikipedia.org/wiki/达特矛斯会议)。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[[2\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-2)他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。

然而，研究人员发现自己大大低估了这一工程的难度，人工智能史上共出现过几次[低潮](https://zh.wikipedia.org/wiki/人工智慧低谷)（也被称作AI之冬）。由于[詹姆斯·莱特希尔](https://zh.wikipedia.org/wiki/詹姆斯·莱特希尔)爵士的批评和国会方面的压力，[美国](https://zh.wikipedia.org/wiki/國防高等研究計劃署)和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[[3\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-3)

尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平](https://zh.wikipedia.org/wiki/強人工智慧)的机器至今仍未出现。[图灵](https://zh.wikipedia.org/wiki/图灵)在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[[4\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-TuringQuote-4)

在21世纪的第一个十年，[机器学习](https://zh.wikipedia.org/wiki/机器学习)得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。

## 先驱

奥特曼写道[[1\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-FOOTNOTEMcCorduck2004-1)：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机](https://zh.wikipedia.org/wiki/自動機)）的实践之中。[[5\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-FOOTNOTEMcCorduck20045–35-5)

### 神话，幻想和预言中的AI

[希腊神话](https://zh.wikipedia.org/wiki/希腊神话)中已经出现了机械人和人造人，如[赫淮斯托斯](https://zh.wikipedia.org/wiki/赫淮斯托斯)的黄金机器人和[皮格马利翁](https://zh.wikipedia.org/wiki/皮格马利翁)的[伽拉忒亚](https://zh.wikipedia.org/wiki/伽拉忒亚)。[[6\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-6)中世纪出现了使用巫术或[炼金术](https://zh.wikipedia.org/wiki/炼金术)将意识赋予无生命物质的传说，如[贾比尔](https://zh.wikipedia.org/wiki/贾比尔)的*Takwin*，[帕拉塞尔苏斯](https://zh.wikipedia.org/wiki/帕拉塞尔苏斯)的[何蒙库鲁兹](https://zh.wikipedia.org/wiki/何蒙库鲁兹)和Judah Loew的[魔像](https://zh.wikipedia.org/wiki/魔像)。[[7\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-7)19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱](https://zh.wikipedia.org/wiki/玛丽·雪莱)的《[弗兰肯斯坦](https://zh.wikipedia.org/wiki/弗兰肯斯坦)》和[卡雷尔·恰佩克](https://zh.wikipedia.org/wiki/卡雷尔·恰佩克)的《罗素姆的万能机器人》。[[8\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-FOOTNOTEMcCorduck200417–25-8)Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[[9\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-FOOTNOTEButler1863-9)至今人工智能仍然是科幻小说的重要元素。

### 自动人偶

主条目：[自动机](https://zh.wikipedia.org/wiki/自动机)

[![img](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Al-jazari_robots.jpg/250px-Al-jazari_robots.jpg)](https://zh.wikipedia.org/wiki/File:Al-jazari_robots.jpg)[加扎利](https://zh.wikipedia.org/wiki/加扎利)的可编程自动人偶（1206年）

许多文明中都有创造自动人偶的杰出工匠，例如[偃师](https://zh.wikipedia.org/wiki/偃师)（中国西周）[[10\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-10)，[希罗](https://zh.wikipedia.org/wiki/希罗)（希腊）[[11\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-11)，[加扎利](https://zh.wikipedia.org/wiki/加扎利)[[12\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-FOOTNOTENick2005-12)和Wolfgang von Kempelen[[13\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-13) 等等。已知最古老的“机器人”是[古埃及](https://zh.wikipedia.org/wiki/古埃及)和[古希腊](https://zh.wikipedia.org/wiki/古希腊)的[圣像](https://zh.wikipedia.org/wiki/聖像)，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯](https://zh.wikipedia.org/wiki/赫耳墨斯·特里斯墨吉斯忒斯)（[赫耳墨斯·特里斯墨吉斯忒斯](https://zh.wikipedia.org/wiki/赫耳墨斯·特里斯墨吉斯忒斯)）写道“当发现神的本性时，人就能够重现他”[[14\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-14)[[15\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-15)。

### 形式推理

人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德](https://zh.wikipedia.org/wiki/亚里士多德)（对三段论逻辑进行了形式分析），[欧几里得](https://zh.wikipedia.org/wiki/欧几里得)（其著作《[几何原本](https://zh.wikipedia.org/wiki/几何原本)》是形式推理的典范），[花剌子密](https://zh.wikipedia.org/wiki/花剌子密)（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉](https://zh.wikipedia.org/wiki/奥卡姆的威廉)和[邓斯·司各脱](https://zh.wikipedia.org/wiki/邓斯·司各脱)。[[16\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Berlinski_2000-16)

[马略卡](https://zh.wikipedia.org/wiki/马略卡)哲学家[拉蒙·柳利](https://zh.wikipedia.org/wiki/拉蒙·柳利)（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[[17\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-17) 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[[18\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-18)Llull的工作对[莱布尼兹](https://zh.wikipedia.org/wiki/莱布尼兹)产生了很大影响，后者进一步发展了他的思想。[[19\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-19)

[![img](https://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Gottfried_Wilhelm_von_Leibniz.jpg/150px-Gottfried_Wilhelm_von_Leibniz.jpg)](https://zh.wikipedia.org/wiki/File:Gottfried_Wilhelm_von_Leibniz.jpg)[莱布尼兹](https://zh.wikipedia.org/wiki/莱布尼兹)猜测人类的思想可以简化为机械计算

在17世纪中，[莱布尼兹](https://zh.wikipedia.org/wiki/莱布尼兹)，[托马斯·霍布斯](https://zh.wikipedia.org/wiki/托马斯·霍布斯)和[笛卡儿](https://zh.wikipedia.org/wiki/笛卡儿)尝试将理性的思考系统化为代数学或几何学那样的体系。[[20\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-20)霍布斯在其著作《[利维坦](https://zh.wikipedia.org/wiki/利维坦_(霍布斯))》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” [[21\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-21)莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字](https://zh.wikipedia.org/wiki/通用表意文字)），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[[22\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-22) 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。

在20世纪，[数理逻辑](https://zh.wikipedia.org/wiki/数理逻辑)研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔](https://zh.wikipedia.org/wiki/乔治·布尔)的《思维的定律》与[弗雷格](https://zh.wikipedia.org/wiki/戈特洛布·弗雷格)的《[概念文字](https://zh.wikipedia.org/wiki/概念文字)》。基于弗雷格的系统，[罗素](https://zh.wikipedia.org/wiki/罗素)和[怀特海](https://zh.wikipedia.org/wiki/怀特海)在他们于1913年出版的巨著《[数学原理](https://zh.wikipedia.org/wiki/数学原理)》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特](https://zh.wikipedia.org/wiki/希尔伯特)，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” [[16\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Berlinski_2000-16)这个问题的最终回答由[哥德尔不完备定理](https://zh.wikipedia.org/wiki/哥德尔不完备定理)，[图灵机](https://zh.wikipedia.org/wiki/图灵机)和[Alonzo Church](https://zh.wikipedia.org/wiki/Alonzo_Church)的[λ演算](https://zh.wikipedia.org/wiki/Λ演算)给出。[[16\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Berlinski_2000-16)[[23\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-23)他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。

[![img](https://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Classic_shot_of_the_ENIAC.jpg/250px-Classic_shot_of_the_ENIAC.jpg)](https://zh.wikipedia.org/wiki/File:Classic_shot_of_the_ENIAC.jpg)在摩尔学校的电气工程的ENIAC计算机

[邱奇-图灵论题](https://zh.wikipedia.org/wiki/邱奇-图灵论题)暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机](https://zh.wikipedia.org/wiki/图灵机)：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[[16\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Berlinski_2000-16)[[24\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-24)

### 计算机科学

用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇](https://zh.wikipedia.org/wiki/查尔斯·巴贝奇)设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝](https://zh.wikipedia.org/wiki/愛達·勒芙蕾絲)预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[[25\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Menabrea1843-25)（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数](https://zh.wikipedia.org/wiki/伯努利数)的方法。）

第一批现代计算机是[二战](https://zh.wikipedia.org/wiki/二战)期间建造的大型译码机（包括Z3，[ENIAC](https://zh.wikipedia.org/wiki/ENIAC)和Colossus等）。[[26\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-26)后两个机器的理论基础是[图灵](https://zh.wikipedia.org/wiki/图灵)和[约翰·冯·诺伊曼](https://zh.wikipedia.org/wiki/约翰·冯·诺伊曼)提出和发展的学说。[[27\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-27)

## 人工智能的诞生：1943 - 1956

[[28\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-28)在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。

### 控制论与早期神经网络

[![img](https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/BRL61-IBM_702.jpg/220px-BRL61-IBM_702.jpg)](https://zh.wikipedia.org/wiki/File:BRL61-IBM_702.jpg)IBM 702：第一代AI研究者使用的电脑

最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳](https://zh.wikipedia.org/wiki/诺伯特·维纳)的[控制论](https://zh.wikipedia.org/wiki/控制论)描述了电子网络的控制和稳定性。[克劳德·香农](https://zh.wikipedia.org/wiki/克劳德·香农)提出的[信息论](https://zh.wikipedia.org/wiki/信息论)则描述了[数字信号](https://zh.wikipedia.org/wiki/数字信号)（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[[29\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-29)

这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[[30\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-30)

Walter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“[神经网络](https://zh.wikipedia.org/wiki/神经网络)”的学者。[[31\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-31)[马文·明斯基](https://zh.wikipedia.org/wiki/马文·明斯基)是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为[SNARC](https://zh.wikipedia.org/w/index.php?title=SNARC&action=edit&redlink=1)。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。

### 游戏AI

1951年，[克里斯托弗·斯特雷奇](https://zh.wikipedia.org/wiki/克里斯托弗·斯特雷奇)使用[曼彻斯特大学](https://zh.wikipedia.org/wiki/曼彻斯特大学)的Ferranti Mark 1机器写出了一个[西洋跳棋](https://zh.wikipedia.org/wiki/西洋跳棋)（checkers）程序；[迪特里希·普林茨](https://zh.wikipedia.org/w/index.php?title=迪特里希·普林茨&action=edit&redlink=1)（Dietrich Prinz）则写出了一个[国际象棋](https://zh.wikipedia.org/wiki/国际象棋)程序。[[32\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-32)[亚瑟·李·塞谬尔](https://zh.wikipedia.org/wiki/亞瑟·李·塞謬爾)（Arthur Samuel）在五十年代中期和六十年代初开发的国际象棋程序的棋力已经可以挑战具有相当水平的业余爱好者。[[33\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-33)游戏AI一直被认为是评价AI进展的一种标准。

### 图灵测试

1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。[[34\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-34)由于注意到“智能”这一概念难以确切定义，他提出了著名的[图灵测试](https://zh.wikipedia.org/wiki/图灵测试)：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。[[35\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-35)图灵测试是人工智能哲学方面第一个严肃的提案。

### 符号推理与“逻辑理论家”程序

50年代中期，随着数字计算机的兴起，一些科学家直觉地感到可以进行数字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。[[36\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-36)

1955年，[艾伦·纽厄尔](https://zh.wikipedia.org/wiki/艾伦·纽厄尔)和后来荣获诺贝尔奖的[赫伯特·西蒙](https://zh.wikipedia.org/wiki/赫伯特·西蒙)在J. C. Shaw的协助下开发了“[逻辑理论家](https://zh.wikipedia.org/wiki/逻辑理论家)（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。[[37\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-37)Simon认为他们已经“解决了神秘的[心/身问题](https://zh.wikipedia.org/wiki/心身二分法)，解释了物质构成的系统如何获得心灵的性质。”[[38\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-38) （这一断言的哲学立场后来被[约翰·罗杰斯·希尔勒](https://zh.wikipedia.org/wiki/约翰·罗杰斯·希尔勒)称为“强人工智能”，即机器可以像人一样具有思想。）[[39\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-39)

### 1956年达特茅斯会议：AI的诞生

主条目：[达特矛斯会议](https://zh.wikipedia.org/wiki/达特矛斯会议)

1956年[达特矛斯会议](https://zh.wikipedia.org/wiki/达特矛斯会议)[[40\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-40)的组织者是[马文·明斯基](https://zh.wikipedia.org/wiki/马文·明斯基)，[约翰·麦卡锡](https://zh.wikipedia.org/wiki/约翰·麦卡锡)和另两位资深科学家[克劳德·香农](https://zh.wikipedia.org/wiki/克劳德·香农)以及内森·罗彻斯特（Nathan Rochester），后者来自[IBM](https://zh.wikipedia.org/wiki/IBM)。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” [[41\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-41)与会者包括[雷·索罗门诺夫](https://zh.wikipedia.org/w/index.php?title=雷·索羅門諾夫&action=edit&redlink=1)（Ray Solomonoff），奥利佛·塞尔弗里奇（Oliver Selfridge），Trenchard More，亚瑟·山谬尔（Arthur Samuel），[艾伦·纽厄尔](https://zh.wikipedia.org/wiki/艾伦·纽厄尔)和[赫伯特·西蒙](https://zh.wikipedia.org/wiki/赫伯特·西蒙)，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。[[42\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-42)会上纽厄尔和西蒙讨论了“逻辑理论家”，而[麦卡锡](https://zh.wikipedia.org/wiki/约翰·麦卡锡)则说服与会者接受“人工智能”一词作为本领域的名称。[[43\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-43)1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。[[44\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-44)

## 黄金年代：1956 - 1974

奥特曼会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：[[45\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-45)计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。[[46\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-46) 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。[[47\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-47) [DARPA](https://zh.wikipedia.org/wiki/DARPA)（[国防高等研究计划署](https://zh.wikipedia.org/wiki/國防高等研究計劃署)）等政府机构向这一新兴领域投入了大笔资金。[[48\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-48)

### 研究工作

从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。

#### 搜索式推理

许多AI程序使用相同的基本[算法](https://zh.wikipedia.org/wiki/算法)。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行[回溯](https://zh.wikipedia.org/wiki/回溯法)。这就是“搜索式推理”。[[49\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-49)

这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用[启发式算法](https://zh.wikipedia.org/wiki/启发式算法)去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。[[50\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-50)

艾伦·纽厄尔和赫伯特·西蒙试图通过其“[通用解题器](https://zh.wikipedia.org/wiki/一般问题解决器)（General Problem Solver）”程序，将这一算法推广到一般情形。[[51\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-51)另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉宁特（Herbert Gelernter）的几何定理证明机（1958）和马文·李·闵斯基的学生James Slagle开发的SAINT（1961）。[[52\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-52)还有一些程序通过搜索目标和子目标作出决策，如[斯坦福大学](https://zh.wikipedia.org/wiki/斯坦福大学)为控制机器人Shakey而开发的STRIPS系统。[[53\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-53)

[![img](https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/250px-Semantic_Net.svg.png)](https://zh.wikipedia.org/wiki/File:Semantic_Net.svg)一个语义网的例子

#### 自然语言

AI研究的一个重要目标是使计算机能够通过[自然语言](https://zh.wikipedia.org/wiki/自然语言处理)（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。[[54\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-54)

如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“[语义网](https://zh.wikipedia.org/wiki/语义网)（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发；[[55\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-55) 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。[[56\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-56)

Joseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。[[57\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-57)

#### 微世界

60年代后期，[麻省理工大学](https://zh.wikipedia.org/wiki/麻省理工大学)AI实验室的马文·闵斯基和[西摩尔·派普特](https://zh.wikipedia.org/wiki/西摩爾·派普特)建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。[[58\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-58)

在这一指导思想下，[杰拉德·杰伊·萨斯曼](https://zh.wikipedia.org/wiki/傑拉德·傑伊·薩斯曼)（研究组长），阿道佛·古兹曼（Adolfo Guzman），[大卫·瓦尔兹](https://zh.wikipedia.org/w/index.php?title=大衛·瓦爾茲&action=edit&redlink=1)（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在[机器视觉](https://zh.wikipedia.org/wiki/机器视觉)领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的[SHRDLU](https://zh.wikipedia.org/wiki/SHRDLU)，它能用普通的英语句子与人交流，还能作出决策并执行操作。[[59\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-59)

### 乐观思潮

第一代AI研究者们曾作出了如下预言:

- 1958年，[艾伦·纽厄尔](https://zh.wikipedia.org/wiki/艾伦·纽厄尔)和[赫伯特·西蒙](https://zh.wikipedia.org/wiki/赫伯特·西蒙)：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”[[60\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-60)。
- 1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”[[61\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-61)
- 1967年，[马文·闵斯基](https://zh.wikipedia.org/wiki/馬文·閔斯基)：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”[[62\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-62)
- 1970年，马文·闵斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”[[63\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-63)

### 经费

1963年6月，[MIT](https://zh.wikipedia.org/wiki/麻省理工大学)从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。[[64\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-64)ARPA还对艾伦·纽厄尔和赫伯特·西蒙在[卡内基梅隆大学](https://zh.wikipedia.org/wiki/卡内基梅隆大学)的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。[[65\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-65)另一个重要的AI实验室于1965年由Donald Michie在[爱丁堡大学](https://zh.wikipedia.org/wiki/爱丁堡大学)建立。[[66\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-66)在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。[[67\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-67)

经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。[[68\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-68)这导致了MIT无约无束的研究氛围及其[hacker](https://zh.wikipedia.org/wiki/Hacker)文化的形成，[[69\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-69)但是好景不长。

## 第一次AI低谷：1974 - 1980

到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。[[70\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-70)同时，由于马文·闵斯基对[感知器](https://zh.wikipedia.org/wiki/感知器)的激烈批评，[联结主义](https://zh.wikipedia.org/wiki/联结主义)（即[神经网络](https://zh.wikipedia.org/wiki/神经网络)）销声匿迹了十年。[[71\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Perceptrons-71)70年代后期，尽管遭遇了公众的误解，AI在[逻辑编程](https://zh.wikipedia.org/wiki/逻辑编程)，常识推理等一些领域还是有所进展。[[72\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-72)

### 问题

70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。[[73\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-73)AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。[[74\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-74)

- 计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，罗斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。[[75\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-75)1976年，[汉斯·莫拉维克](https://zh.wikipedia.org/wiki/汉斯·莫拉维克)指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的[提升](https://zh.wikipedia.org/wiki/摩尔定律)，问题逐渐会变得简单。[[76\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-76)
- [计算复杂性](https://zh.wikipedia.org/wiki/計算複雜性理論)和指数爆炸。1972年[理查德·卡普](https://zh.wikipedia.org/wiki/理查德·卡普)根据[史提芬·古克](https://zh.wikipedia.org/wiki/史提芬·古克)于1971年提出的[Cook-Levin理论](https://zh.wikipedia.org/wiki/Cook-Levin理論)证明，[许多问题](https://zh.wikipedia.org/wiki/卡普的二十一個NP-完全問題)只可能在[指数时间](https://zh.wikipedia.org/wiki/指數時間)内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。[[77\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-77)
- [常识](https://zh.wikipedia.org/wiki/常識)与推理。许多重要的AI应用，例如[机器视觉](https://zh.wikipedia.org/wiki/机器视觉)和[自然语言](https://zh.wikipedia.org/wiki/自然语言)，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。[[78\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-78)
- [莫拉维克悖论](https://zh.wikipedia.org/wiki/莫拉維克悖論)。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期[机器视觉](https://zh.wikipedia.org/wiki/机器视觉)和[机器人](https://zh.wikipedia.org/wiki/机器人)方面进展缓慢的原因。[[79\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-79)
- 框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及[自动规划](https://zh.wikipedia.org/w/index.php?title=自动规划&action=edit&redlink=1)（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如[非单调逻辑](https://zh.wikipedia.org/wiki/非单调逻辑)（non-monotonic logics）和[模态逻辑](https://zh.wikipedia.org/wiki/模态逻辑)（modal logics））。[[80\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-80)

### 停止拨款

由于AI的进展缓慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。[[81\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-81)1973年[詹姆斯·莱特希尔](https://zh.wikipedia.org/wiki/詹姆斯·莱特希尔)针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮[[82\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-82)（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。[[83\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-83)DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。[[84\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-84)到了1974年已经很难再找到对AI项目的资助。

Hans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。[[85\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-85)还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。[[86\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-86)

### 来自大学的批评

一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为[哥德尔不完备定理](https://zh.wikipedia.org/wiki/哥德尔不完备定理)已经证明[形式系统](https://zh.wikipedia.org/wiki/形式系统)（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。[[87\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-87)修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。[[88\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-88)[[89\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-89) 约翰·希尔勒于1980年提出“[中文房间](https://zh.wikipedia.org/wiki/中文房间)”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“[意向性](https://zh.wikipedia.org/wiki/意向性)（intentionality）”问题。希尔勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。[[90\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-90)

AI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而[计算复杂性](https://zh.wikipedia.org/wiki/计算复杂性)和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。马文·闵斯基提到德雷福斯和希尔勒时说，“他们误解了，所以应该忽略”。[[91\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-91)在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。[[92\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-92) ELIZA程序的作者约瑟夫·维森鲍姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。[[93\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-93)

约瑟夫·维森鲍姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为约瑟夫·维森鲍姆对他的程序没有贡献，但这于事无补。1976年约瑟夫·维森鲍姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。[[94\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-94)

### 感知器与联结主义遭到冷落

[感知器](https://zh.wikipedia.org/wiki/感知器)是[神经网络](https://zh.wikipedia.org/wiki/神经网络)的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。

1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：[联结主义](https://zh.wikipedia.org/wiki/联结主义)的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。[[71\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Perceptrons-71)

### “简约派（the neats）”：逻辑，Prolog语言和专家系统

早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。[[95\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-95)1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。[[96\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-96)70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言[Prolog](https://zh.wikipedia.org/wiki/Prolog)。[[97\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-97)Prolog使用一组逻辑(与“规则”和“[生产规则](https://zh.wikipedia.org/w/index.php?title=生產規則&action=edit&redlink=1)”密切相关的“[霍恩子句](https://zh.wikipedia.org/wiki/霍恩子句)”)，并允许进行可处理的计算。规则持续带来影响，为[爱德华·费根鲍姆](https://zh.wikipedia.org/wiki/愛德華·費根鮑姆)的[专家系统](https://zh.wikipedia.org/wiki/專家系統)以及艾伦·纽厄尔和赫伯特·西蒙的工作奠定基础，使其完成了[Soar](https://zh.wikipedia.org/wiki/Soar_(認知架構))及[认知统一理论](https://zh.wikipedia.org/wiki/認知統一理論)。[[98\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-98)

Dreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，[阿摩司·特沃斯基](https://zh.wikipedia.org/wiki/阿摩司·特沃斯基)，Daniel Kahneman等人的实验证明了这一点。[[99\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-99)McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。[[100\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-100)

### “芜杂派（the scruffies）”：框架和脚本

对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。[[101\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-101)Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。[[102\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-102)

在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。[[103\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-103) 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。

## 繁荣：1980—1987

在80年代，一类名为“[专家系统](https://zh.wikipedia.org/wiki/专家系统)”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。

### 专家系统获得赏识

[专家系统](https://zh.wikipedia.org/wiki/专家系统)是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。[[104\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-104)

专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。[[105\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-105)

1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。[[106\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-106)全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。[[107\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-107)

### 知识革命

专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。 [[108\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-108) Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” [[109\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-109)知识库系统和知识工程成为了80年代AI研究的主要方向。[[110\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-110)

第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。[[111\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-111)

### 重获拨款：第五代工程

1981年，日本经济产业省拨款八亿五千万美元支持[第五代计算机](https://zh.wikipedia.org/wiki/第五代電腦)项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。[[112\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-112)令“芜杂派”不满的是，他们选用[Prolog](https://zh.wikipedia.org/wiki/Prolog)作为该项目的主要编程语言。[[113\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-113)

其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。[[114\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-114)[[115\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Norvig_25-115) DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。[[116\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-116)

[![img](https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Hopfield-net.png/220px-Hopfield-net.png)](https://zh.wikipedia.org/wiki/File:Hopfield-net.png)一个四节点的Hopfield网络.

### 联结主义的重生

1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了[反向传播算法](https://zh.wikipedia.org/wiki/反向传播算法)，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。[[115\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Norvig_25-115)[[117\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-117)

1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“[分布式并行处理](https://zh.wikipedia.org/wiki/分布式并行处理)”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。[[115\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-Norvig_25-115)[[118\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-118)

## 第二次AI低谷：1987—1993

80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。

### 人工智能的低谷

“[AI之冬](https://zh.wikipedia.org/wiki/人工智慧低谷)”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。[[119\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-119)事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。

变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。[[120\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-120)

XCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（[qualification problem](https://zh.wikipedia.org/w/index.php?title=Qualification_problem&action=edit&redlink=1)））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。[[121\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-121)

到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。[[122\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-122)

直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。[[123\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-FifthGenEnd-123) 与其他AI项目一样，期望比真正可能实现的要高得多。[[123\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-FifthGenEnd-123)

### 躯体的重要性：Nouvelle AI与嵌入式推理

80年代后期，一些研究者根据机器人学的成就提出了一种全新的人工智能方案。[[124\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-124) 他们相信，为了获得真正的智能，机器必须具有躯体 - 它需要感知，移动，生存，与这个世界交互。他们认为这些感知运动技能对于常识推理等高层次技能是至关重要的，而抽象推理不过是人类最不重要，也最无趣的技能（参见[莫拉维克悖论](https://zh.wikipedia.org/wiki/莫拉維克悖論)）。[[125\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-125)他们号召“[自底向上](https://zh.wikipedia.org/wiki/自上而下和自下而上設計)”地创造智能，这一主张复兴了从60年代就沉寂下来的控制论。

另一位先驱是在理论神经科学上造诣深厚的David Marr，他于70年代来到MIT指导视觉研究组的工作。他排斥所有符号化方法（不论是McCarthy的逻辑学还是Minsky的框架），认为实现AI需要自底向上地理解视觉的物理机制，而符号处理应在此之后进行。[[126\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-126)

在发表于1990年的论文“大象不玩象棋（Elephants Don't Play Chess）”中，机器人研究者Rodney Brooks针对“[物理符号系统假设](https://zh.wikipedia.org/wiki/物理符號系統)”提出批评，他认为符号是可有可无的，因为“这个世界就是描述它自己最好的模型。它总是最新的。它总是包括了需要研究的所有细节。诀窍在于正确地，足够频繁地感知它。” [[127\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-127)在80年代和90年代也有许多认知科学家反对基于符号处理的智能模型，认为身体是推理的必要条件，这一理论被称为“[具身的心灵/理性/ 认知](https://zh.wikipedia.org/wiki/體化認知)（embodied mind/reason/cognition）”论题。[[128\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-128)

## AI：1993—2011

现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。[[129\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-129)AI比以往的任何时候都更加谨慎，却也更加成功。

### 里程碑和摩尔定律

1997年5月11日，深蓝成为战胜国际象棋世界冠军[卡斯帕罗夫](https://zh.wikipedia.org/wiki/卡斯帕羅夫)的第一个计算机系统。[[130\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-130)2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。[[131\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-131)2009年，[蓝脑计划](https://zh.wikipedia.org/wiki/藍腦計畫)声称已经成功地模拟了部分鼠脑。2011年，[IBM 沃森](https://zh.wikipedia.org/w/index.php?title=IBM_沃森_(人工智慧程序)&action=edit&redlink=1)参加《[危险边缘](https://zh.wikipedia.org/wiki/危险边缘)》节目，在最后一集打败了人类选手。2016年3月，[AlphaGo](https://zh.wikipedia.org/wiki/AlphaGo)击败[李世乭](https://zh.wikipedia.org/wiki/李世乭)，成为第一个不让子而击败职业[围棋](https://zh.wikipedia.org/wiki/圍棋)棋士的[电脑围棋](https://zh.wikipedia.org/wiki/电脑围棋)程式。2017年5月，AlphaGo在[中国乌镇围棋峰会](https://zh.wikipedia.org/wiki/中国乌镇围棋峰会)的三局比赛中击败[[132\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-wuzhensecond-132)当时世界排名第一[[133\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-133)[[134\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-134)的中国棋手[柯洁](https://zh.wikipedia.org/wiki/柯洁)。

这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。[[135\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-135)事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。[[136\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-136)这种剧烈增长可以用[摩尔定律](https://zh.wikipedia.org/wiki/摩尔定律)描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。

### 智能代理

90年代，被称为“[智能代理](https://zh.wikipedia.org/wiki/智能代理)”的新范式被广泛接受。[[137\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-137)尽管早期研究者提出了模块化的分治策略，[[138\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-138) 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。[[139\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-R27-139)当经济学中的“[理性代理](https://zh.wikipedia.org/wiki/理性主体)（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。

智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。[[140\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-140)

这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的[代理架构](https://zh.wikipedia.org/w/index.php?title=代理架构&action=edit&redlink=1)（像Newell的[Soar](https://zh.wikipedia.org/wiki/Soar_(認知架構))那样），允许研究者们应用交互的智能代理建立起通用的智能系统。[[139\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-R27-139)[[141\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-141)

### “简约派”的胜利

越来越多的AI研究者们开始开发和使用复杂的数学工具。[[142\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-142)人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。[[143\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-143) Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。[[144\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-RN25-144)[[145\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-145)

Judea Pearl发表于1988年的名著[[146\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-146)将概率论和决策理论引入AI。现已投入应用的新工具包括[贝叶斯网络](https://zh.wikipedia.org/wiki/贝叶斯网络)，[隐马尔可夫模型](https://zh.wikipedia.org/wiki/隐马尔可夫模型)，[信息论](https://zh.wikipedia.org/wiki/信息论)，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。[[144\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-RN25-144)

### 幕后的AI

AI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，[[147\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-147)这些解决方案在产业界起到了重要作用。[[148\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-148)应用了AI技术的有[数据挖掘](https://zh.wikipedia.org/wiki/数据挖掘)，[工业机器人](https://zh.wikipedia.org/wiki/工业机器人)，[物流](https://zh.wikipedia.org/wiki/物流)[[149\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-149)，[语音识别](https://zh.wikipedia.org/wiki/语音识别)[[150\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-150)，银行业软件[[151\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-CNN7242006-151)，医疗诊断[[151\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-CNN7242006-151)和[Google](https://zh.wikipedia.org/wiki/Google)搜索引擎等。[[152\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-152)

AI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。[[153\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-153)[尼克·博斯特罗姆](https://zh.wikipedia.org/wiki/尼克·博斯特罗姆)解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”[[154\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-154)

90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如[信息学](https://zh.wikipedia.org/wiki/信息学)，[知识系统](https://zh.wikipedia.org/w/index.php?title=知识系统&action=edit&redlink=1)，[认知系统](https://zh.wikipedia.org/w/index.php?title=认知系统&action=edit&redlink=1)或[计算智能](https://zh.wikipedia.org/w/index.php?title=计算智能&action=edit&redlink=1)。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”[[155\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-155)[[156\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-156)[[157\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-157)

### HAL 9000在哪里?

1968年[亚瑟·克拉克](https://zh.wikipedia.org/wiki/亞瑟·克拉克)和[史丹利·库柏力克](https://zh.wikipedia.org/wiki/史丹利·庫柏力克)创作的《“[2001太空漫游](https://zh.wikipedia.org/wiki/2001太空漫游)”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。[[158\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-158)

“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。[[159\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-159) Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，约翰·麦卡锡则归咎于资格问题（[qualification problem](https://zh.wikipedia.org/w/index.php?title=Qualification_problem&action=edit&redlink=1)）。[[160\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-160)[雷蒙德·库茨魏尔](https://zh.wikipedia.org/wiki/雷蒙德·库茨魏尔)相信问题在于计算机性能，根据[摩尔定律](https://zh.wikipedia.org/wiki/摩尔定律)，他预测具有人类智能水平的机器将在2029年出现。[[161\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-161)杰夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。[[162\]](https://zh.wikipedia.org/wiki/人工智能史#cite_note-162)还有许多别的解释，每一个都对应着一个正在进行的研究计划。

## 深度学习，大数据和通用人工智能：2011至今

进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的[机器学习](https://zh.wikipedia.org/wiki/机器学习)技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。

到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。

### 深度学习

主条目：[深度学习](https://zh.wikipedia.org/wiki/深度学习)

深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。

然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。

现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如[MNIST数据集](https://zh.wikipedia.org/w/index.php?title=MNIST数据集&action=edit&redlink=1)（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。

### 大数据

主条目：[大数据](https://zh.wikipedia.org/wiki/大數據)

大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。

### 强化学习与大型语言模型

主条目：[通用人工智能](https://zh.wikipedia.org/wiki/通用人工智慧)

强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序[ChatGPT](https://zh.wikipedia.org/wiki/ChatGPT)基于[GPT-3.5](https://zh.wikipedia.org/wiki/GPT-3)架构的[大型语言模型](https://zh.wikipedia.org/wiki/大型语言模型)并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。